{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from transformers import AutoTokenizer, TFBertModel, TFAutoModelForSeq2SeqLM\n",
    "tokenizer = PegasusTokenizer.from_pretrained('huggingface/legal-pegasus')\n",
    "model = PegasusForConditionalGeneration.from_pretrained('huggingface/legal-pegasus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(cleaned_text, cleaned_summary_text, tokenizer):\n",
    "    original_text_tokened = tokenizer(cleaned_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "    summary_tokened = tokenizer(cleaned_summary_text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "    return original_text_tokened, summary_tokened\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', '[DATE]', text)\n",
    "    text = re.sub(r'\\b\\d{4}\\b', '[YEAR]', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\bAIR\\s\\d{4}\\sSC\\s\\d{3,4}\\b', '[CITATION]', text)\n",
    "    legal_dict = {\n",
    "        'hereinabove': 'above',\n",
    "        'hereinafter': 'below',\n",
    "        'plaintiff': 'claimant',\n",
    "        'defendant': 'respondent'\n",
    "    }\n",
    "    for term, replacement in legal_dict.items():\n",
    "        text = text.replace(term, replacement)\n",
    "    boilerplate_phrases = [\n",
    "        'the learned counsel submitted that',\n",
    "        'in light of the above discussion',\n",
    "        'the facts of the case are as follows'\n",
    "    ]\n",
    "    for phrase in boilerplate_phrases:\n",
    "        text = text.replace(phrase, '')\n",
    "    return text\n",
    "\n",
    "def clean_summary_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def read(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        return text\n",
    "\n",
    "# Function to load and preprocess data using a data pipeline\n",
    "def load_and_preprocess_data(file_path):\n",
    "    judgment_text_path = file_path[0].numpy().decode('utf-8')\n",
    "    summary_text_path = file_path[1].numpy().decode('utf-8')\n",
    "\n",
    "    judgment_text = read(judgment_text_path)\n",
    "    summary_text = read(summary_text_path)\n",
    "    \n",
    "    cleaned_judgment_text = clean_text(judgment_text)\n",
    "    cleaned_summary_text = clean_summary_text(summary_text)\n",
    "    \n",
    "    # Tokenization\n",
    "    original_text_tokened, summary_tokened = tokenization(cleaned_judgment_text, cleaned_summary_text, tokenizer)\n",
    "    \n",
    "    return original_text_tokened['input_ids'][0], original_text_tokened['attention_mask'][0], summary_tokened['input_ids'][0]\n",
    "\n",
    "# Dataset directory paths\n",
    "dataset_dir = \"C:/Users/prasa/Downloads/7152317/dataset/dataset/IN-Abs\"\n",
    "train_judgement_dir = os.path.join(dataset_dir, 'train-data', 'judgement')\n",
    "train_summary_dir = os.path.join(dataset_dir, 'train-data', 'summary')\n",
    "\n",
    "# Prepare file paths for judgments and summaries\n",
    "train_files = [(os.path.join(train_judgement_dir, file), os.path.join(train_summary_dir, file)) for file in os.listdir(train_judgement_dir)]\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "train_dataset = train_dataset.map(lambda x: tf.py_function(load_and_preprocess_data, [x], [tf.int32, tf.int32, tf.int32]))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_files))\n",
    "train_dataset = train_dataset.padded_batch(16, padded_shapes=([None], [None], [None]))\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_judgement_dir = os.path.join(dataset_dir, 'test-data', 'judgement')\n",
    "test_summary_dir= os.path.join(dataset_dir, 'test-data', 'summary')\n",
    "test_files = [(os.path.join(test_judgement_dir, file), os.path.join(test_summary_dir, file)) for file in os.listdir(test_judgement_dir)]\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "test_dataset = test_dataset.map(lambda x: tf.py_function(load_and_preprocess_data, [x], [tf.int32, tf.int32, tf.int32]))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=len(test_files))\n",
    "test_dataset = test_dataset.padded_batch(16, padded_shapes=([None], [None], [None]))\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(labels, y_pred):\n",
    "    cross_entropy_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(labels, y_pred)\n",
    "    return cross_entropy_loss\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_mask, decoder_input_ids, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        input_attention_mask = tf.cast(tf.not_equal(input_ids, tokenizer.pad_token_id), tf.int32)\n",
    "        decoder_attention_mask = tf.cast(tf.not_equal(decoder_input_ids, tokenizer.pad_token_id), tf.int32)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=input_attention_mask, decoder_input_ids=decoder_input_ids, training=True).logits\n",
    "        loss = custom_loss(labels, outputs)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_dataset:\n",
    "        input_ids, attention_mask, decoder_input_ids = batch\n",
    "        labels = decoder_input_ids[:, 1:]\n",
    "        decoder_input_ids = decoder_input_ids[:, :-1]\n",
    "        \n",
    "        train_step(input_ids, attention_mask, decoder_input_ids, labels)\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss.result()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(input_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"tf\").input_ids\n",
    "    summary_ids = model.generate(input_ids, max_length=150, num_beams=2, length_penalty=2.0, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = load_metric(\"rouge\")\n",
    "\n",
    "# def evaluate_model(model, test_dataset):\n",
    "#     for batch in test_dataset:\n",
    "#         input_ids, attention_mask, decoder_input_ids = batch\n",
    "#         labels = decoder_input_ids[:, 1:]\n",
    "#         outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "#         decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "#         decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "#         metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "#     final_score = metric.compute()\n",
    "#     return final_score\n",
    "\n",
    "# bart_scores = evaluate_model(bart_model, test_dataset)\n",
    "# pegasus_scores = evaluate_model(pegasus_model, test_dataset)\n",
    "\n",
    "# print(f\"BART Scores: {bart_scores}\")\n",
    "# print(f\"Pegasus Scores: {pegasus_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
